{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化：目的是对节点的特征向量做行L1归一化，每一行的和是1，具体实现是创建了一个每一行和的倒数的对角矩阵乘以特征向量（和度的-1乘X获得邻居求和的平均值同理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0],\n",
       "        [0, 1, 2],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "data = [1, 1, 2]\n",
    "row = [0, 1, 1]\n",
    "col = [0, 1, 2]\n",
    "matrix = sp.coo_matrix((data, (row, col)), shape=(3, 3))\n",
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [3],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "rowsum  = np.array(matrix.sum(1))\n",
    "rowsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.power cannot be used in float，change it to np.float_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzq/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in float_power\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.33333333, 0.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_inv = np.float_power(rowsum, -1).flatten()\n",
    "r_inv[np.isinf(r_inv)] = 0.\n",
    "r_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.33333333, 0.        ],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mat_inv = sp.diags(r_inv)\n",
    "r_mat_inv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.33333333, 0.66666667],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = r_mat_inv.dot(matrix)\n",
    "features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csr_matrix:data是矩阵的非零值，indices是和非零值一一对应的所在行的列位置，indptr是总计非零值的个数，第一个元素默认是0，从第二个元素开始记录每行非零的值个数，这个再结合data按照顺序就可以确定一个稀疏矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 2],\n",
       "        [0, 3, 4],\n",
       "        [0, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr = np.array([0, 2, 4, 6])\n",
    "indices = np.array([0, 2, 1, 2, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "matrix = sp.csr_matrix((data, indices, indptr), shape=(3, 3))\n",
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lil_matrix:可以切片，更新数据，非常灵活。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0],\n",
       "        [0, 1, 2],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1, 1, 2]\n",
    "row = [0, 1, 1]\n",
    "col = [0, 1, 2]\n",
    "matrix = sp.coo_matrix((data, (row, col)), shape=(3, 3))\n",
    "matrix.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 1],\n",
       "        [0, 1, 2],\n",
       "        [0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = matrix.tolil()\n",
    "matrix[0,2] = matrix[1,1]\n",
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzq/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/home/lzq/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "/home/lzq/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/scipy/sparse/lil.py:518: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not x.flags.writeable:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 2],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[[0,2]] = matrix[1]\n",
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.sparse_placeholder:稀疏占位符,和coo_matrix配合使用,例子如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4, 0, 9, 0],\n",
       "        [0, 7, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.array([0, 0, 1, 3])  # 第几行\n",
    "col = np.array([0, 2, 1, 3])  # 第几列\n",
    "data = np.array([4, 9, 7, 5])  # 值\n",
    "tmp = sp.coo_matrix((data, (row, col)), shape=(4, 4))\n",
    "tmp.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从TensorFlow 的名字就可以看出张量( tensor ）是一个很重要的概念。在TensorFlow\n",
    "程序中，所有的数据都通过张量的形式来表示。从功能的角度上看，张量可以被简单理解\n",
    "为多维数组。其中零阶张量表示标量（ scalar ） ，也就是一个数① ： 第一阶张量为向量C vector),\n",
    "也就是一个一维数组；第n 阶张量可以理解为一个n 维数组。但张量在Tensor Flow 中的实\n",
    "现并不是直接采用数组的形式，它只是对TensorFlow 中运算结果的引用。在张量中并没有\n",
    "真正保存数字，它保存的是如何得到这些数字的计算过程。还是以向量加法为例，当运行\n",
    "如下代码时，并不会得到加法的结果，而会得到对结果的一个引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.constant 是一个计算，这个计算的结果为一个张量， 保存在变量a中。\n",
    "a= tf . constant([1.0, 2.0] , name =\"a\")\n",
    "b = tf . constant ( [2.0 , 3.0] , name =\"b\")\n",
    "result = tf.add (a , b , name=\"add\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------tf.sparse_placeholder效果\n",
      "SparseTensorValue(indices=array([[0, 0],\n",
      "       [0, 2],\n",
      "       [1, 1],\n",
      "       [3, 3]]), values=array([4., 9., 7., 5.], dtype=float32), dense_shape=array([4, 4]))\n",
      "-----------tf.sparse_placeholder转化为稠密矩阵\n",
      "[[4. 0. 9. 0.]\n",
      " [0. 7. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 5.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.sparse_placeholder(tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    indices = np.mat([tmp.tocoo().row, tmp.tocoo().col]).transpose()\n",
    "    values = tmp.tocoo().data\n",
    "    shape = tmp.tocoo().shape\n",
    "    # feed_dict传入三元组(坐标，非零，维度)\n",
    "    sp_ten = sess.run(x, feed_dict={x: (indices, values, shape)})\n",
    "    print(\"-----------tf.sparse_placeholder效果\")\n",
    "    print(sp_ten)\n",
    "    dense_tensor = tf.sparse_tensor_to_dense(sp_ten)\n",
    "    print(\"-----------tf.sparse_placeholder转化为稠密矩阵\")\n",
    "    print(sess.run(dense_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coo_matrix转化为三元组格式可以直接传入tf.sparse_placeholder中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse_train，目的保留稀疏矩阵中指定的非空值，其余位置是0。\n",
    "下面代码就是把c矩阵进行[True, False, True, True]的mask之后的dropout结果，结果如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=array([[0, 0],\n",
      "       [1, 0],\n",
      "       [2, 1],\n",
      "       [3, 1]]), values=array([1., 2., 3., 4.], dtype=float32), dense_shape=array([4, 2]))\n",
      "SparseTensorValue(indices=array([[0, 0],\n",
      "       [2, 1],\n",
      "       [3, 1]]), values=array([1., 3., 4.], dtype=float32), dense_shape=array([4, 2]))\n",
      "[[1. 0.]\n",
      " [0. 0.]\n",
      " [0. 3.]\n",
      " [0. 4.]]\n"
     ]
    }
   ],
   "source": [
    "a = [[0, 0], [1, 0], [2, 1], [3, 1]]\n",
    "b = [1, 2, 3, 4]\n",
    "shape = [4, 2]\n",
    "c = tf.sparse_placeholder(tf.float32)\n",
    "d = tf.sparse_retain(c, tf.convert_to_tensor([1, 0, 1, 1]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c, feed_dict={c: (a, b, shape)}))\n",
    "    print(sess.run(d, feed_dict={c: (a, b, shape)}))\n",
    "    print(sess.run(tf.sparse_tensor_to_dense(d), feed_dict={c: (a, b, shape)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试：稀疏矩阵可以乘稠密矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [2. 2.]\n",
      " [0. 3.]\n",
      " [0. 4.]]\n",
      "[[10.  1.]\n",
      " [30.  6.]\n",
      " [15.  6.]\n",
      " [20.  8.]]\n"
     ]
    }
   ],
   "source": [
    "a = [[0, 0], [1, 0], [1, 1], [2, 1], [3, 1]]\n",
    "b = [1, 2, 2, 3, 4]\n",
    "shape = [4, 2]\n",
    "c = tf.sparse_placeholder(tf.float32)\n",
    "d = tf.convert_to_tensor([[10.0, 1.0], [5.0, 2.0]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.sparse_tensor_to_dense(c), feed_dict={c: (a, b, shape)}))\n",
    "    print(sess.run(tf.sparse_tensor_dense_matmul(c, d), feed_dict={c: (a, b, shape)}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tf-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d9242ea4a785d53064e1d88b3b813836542cf8b44600afd2e008c489cf593bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
